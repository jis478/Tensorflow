{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original images:  30\n",
      "ground truth images:  30\n",
      "Tfrecord generation finished\n",
      "original images:  2\n",
      "ground truth images:  2\n",
      "Tfrecord generation finished\n"
     ]
    }
   ],
   "source": [
    "from make_tfrecords import *\n",
    "\n",
    "# 실행\n",
    "tfroecord_sample = TFrecord_Create_For_Unet(train_test = 'train',\n",
    "                        img_folder = '/notebooks/Unet_membrane/unet/data/membrane/train/new_data/',\n",
    "                        img_type = 'png',\n",
    "                        label_name = 'labels',\n",
    "                        tf_record_pre_fix = 'membrane_train',\n",
    "                        nx = 512,\n",
    "                        ny = 512\n",
    "                       )\n",
    "\n",
    "\n",
    "tfrecord = TFrecord_Create_For_Unet(train_test = 'test',\n",
    "                        img_folder = '/notebooks/Unet_membrane/unet/data/membrane/test2/',\n",
    "                        img_type = 'png',\n",
    "                        label_name = '_predict',\n",
    "                        tf_record_pre_fix = 'tfrecords',\n",
    "                        nx = 512,\n",
    "                        ny = 512\n",
    "                       )\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.image.ops\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from modeling import *\n",
    "from dataprovider import *\n",
    "from make_tfrecords import *\n",
    "from layer import *\n",
    "\n",
    "data_provider = Tfrecord_ImageDataProvider(                 \n",
    "                                        train_tfrecord_path = '/notebooks/Unet/unet_tfrecord/membrane_train_train.tfrecords', \n",
    "                                        test_tfrecord_path = '/notebooks/Unet/unet_tfrecord/tfrecords_test.tfrecords', \n",
    "                                        channels = 1, train_batch_size = 4, test_batch_size = 2, \n",
    "                                        nx = 512, ny = 512, n_imgs = 30)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-13 07:38:15,099 Layers 5, features 64, filter size 3x3, pool size: 2x2\n",
      "2019-03-13 07:38:18,391 Removing '/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/prediction2'\n",
      "2019-03-13 07:38:18,652 Removing '/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/model2'\n",
      "2019-03-13 07:38:18,657 Allocating '/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/prediction2'\n",
      "2019-03-13 07:38:18,659 Allocating '/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/model2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122603.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-13 07:38:24,472 Validation loss=0.2764\n",
      "2019-03-13 07:38:24,618 Start optimization\n",
      "2019-03-13 07:38:32,316 Iter 1, Minibatch Loss= 0.3176\n",
      "2019-03-13 07:38:33,252 Iter 2, Minibatch Loss= 0.2971\n",
      "2019-03-13 07:38:34,197 Iter 3, Minibatch Loss= 0.2852\n",
      "2019-03-13 07:38:35,127 Iter 4, Minibatch Loss= 0.2724\n",
      "2019-03-13 07:38:36,051 Iter 5, Minibatch Loss= 0.2582\n",
      "2019-03-13 07:38:36,980 Iter 6, Minibatch Loss= 0.2512\n",
      "2019-03-13 07:38:37,911 Iter 7, Minibatch Loss= 0.2456\n",
      "2019-03-13 07:38:38,834 Iter 8, Minibatch Loss= 0.2393\n",
      "2019-03-13 07:38:38,836 Epoch 0, Average loss: 0.2884, learning rate: 0.0010\n",
      "2019-03-13 07:38:39,071 Validation loss=0.2507\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'store_prediction2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aecceccd4c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bce_dice_coefficient\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/model2/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/prediction2/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/Unet/modeling.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, output_path, training_iters, epochs, dropout, display_step, restore, write_graph, prediction_path)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgts_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_prediction2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'store_prediction2'"
     ]
    }
   ],
   "source": [
    "from modeling import *\n",
    "from dataprovider import *\n",
    "from make_tfrecords import *\n",
    "from layer import *\n",
    "\n",
    "net = Unet(cost = \"bce_dice_coefficient\", layers=5, features_root=64, channels=1) \n",
    "trainer = Trainer(net, data_provider = data_provider, batch_size=4, validation_batch_size = 1,optimizer=\"adam\", lr = 0.001, opt_kwargs={})\n",
    "path = trainer.train(output_path='/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/model2/', prediction_path = '/home/Markkim/Git/Tensorflow/Unet_modified/output/membrane/prediction2/', training_iters=8, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
