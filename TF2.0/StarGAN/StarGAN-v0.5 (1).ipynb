{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, ReLU, Conv2DTranspose, LeakyReLU, Layer, ZeroPadding2D\n",
    "from tensorflow.keras.activations import tanh\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(folder,attr_csv, num, img_size): \n",
    "    ''' data preprocessing'''\n",
    "    domain_list = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "    list_attr_celeba = pd.read_csv(attr_csv)\n",
    "    list_attr_celeba = list_attr_celeba.loc[(list_attr_celeba['Black_Hair'] == 1) | (list_attr_celeba['Blond_Hair'] == 1) | (list_attr_celeba['Brown_Hair'] == 1), domain_list]\n",
    "    list_attr_celeba = list_attr_celeba.replace({-1:0})\n",
    "    list_attr_celeba = list_attr_celeba.loc[list_attr_celeba.apply(lambda x: x['Black_Hair'] + x['Blond_Hair'] + x['Brown_Hair'], axis=1) == 1]\n",
    "    list_attr_celeba = list_attr_celeba.sample(n=num,replace=False)\n",
    "    idx = list(list_attr_celeba.index)\n",
    "    list_attr_celeba = np.array(list_attr_celeba)\n",
    "\n",
    "    img_list = glob.glob(os.path.join(folder, '*'))\n",
    "    X_train = np.zeros((num, img_size, img_size, 3))\n",
    "    for i, img_idx in enumerate(idx):\n",
    "        X_train[i] = (np.array(Image.open(img_list[img_idx]).resize((size,size))) - 127.5) / 127.5\n",
    "\n",
    "    print(\"{} training image loaded \".format(len(X_train)))\n",
    "    print(\"{} x {} original domain dataset loaded\".format(list_attr_celeba.shape[0], list_attr_celeba.shape[1]))\n",
    "    \n",
    "    return X_train, list_attr_celeba\n",
    "\n",
    "def dataset_split(X_train, y_train, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_size)\n",
    "    print(\"Number of train images: {}\".format(len(X_train)))\n",
    "    print(\"Number of train original domain labels: {}\".format(len(y_train)))\n",
    "    print(\"Number of test images: {}\".format(len(X_test)))\n",
    "    print(\"Number of test original domain labels: {}\".format(len(y_test)))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def _preprocessing(image, domain, train=True):\n",
    "    ''' image flip & domain reshape'''\n",
    "    domain = tf.reshape(domain, shape=(-1,1, 1, tf.shape(domain)[-1])) \n",
    "    if train:\n",
    "        image = tf.image.random_flip_left_right(image)     # 50% flip logic is already embedded in tf.image.random_flip_left_right\n",
    "    return image,domain\n",
    "\n",
    "def random_target_domain_generation(batch_size):\n",
    "  ''' target domain generation '''\n",
    "  target_domain_1 = np.random.uniform(low=0., high=3., size=batch_size).astype(np.int32) # facial expression attributes\n",
    "  target_domain_1 = tf.one_hot(target_domain_1, depth=3)\n",
    "  target_domain_2 = np.random.randint(2, size=(batch_size,2)) # male, young attributes\n",
    "  target_domain =  np.concatenate([target_domain_1, target_domain_2], axis=-1)\n",
    "  target_domain = target_domain.reshape((target_domain.shape[0],1,1,target_domain.shape[1]))\n",
    "  return target_domain\n",
    "            \n",
    "def generate_and_save_images(model, step, test_dataset):\n",
    "  ''' generated image saving'''\n",
    "\n",
    "  test_image, _ = next(iter(test_dataset))\n",
    "  target_domain = random_target_domain_generation(tf.shape(test_image)[0])\n",
    "  predictions = model(test_image, target_domain)\n",
    "  fig = plt.figure(figsize=(20,20))\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(predictions[i, :, :, :] * 127.5 + 127.5)\n",
    "    plt.axis('off')        \n",
    "  plt.savefig('image_at_step_{:04d}.png'.format(step))\n",
    "  plt.show()\n",
    "  \n",
    "def input_merge(images, domain):\n",
    "  ''' input image and domain merge'''\n",
    "  batch_size = images.shape[0]\n",
    "  image_size = images.shape[1] \n",
    "  channels = domain.shape[-1] \n",
    "  domain = np.squeeze(domain, axis=(1,2))  \n",
    "  merged = np.zeros([batch_size,image_size,image_size,channels])\n",
    "  for batch in range(batch_size):\n",
    "    temp = tf.broadcast_to(domain[batch], [image_size,image_size,channels])\n",
    "    merged[batch] = temp\n",
    "  merged = tf.concat([images, merged], axis=-1)\n",
    "  return merged  \n",
    "\n",
    "\n",
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "  '''InstanceNormalization for only 4-rank Tensor (image data)'''\n",
    "\n",
    "  def __init__(self, epsilon=1e-5):\n",
    "    super(InstanceNormalization, self).__init__()\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape)\n",
    "    param_shape = shape[-1]\n",
    "    self.gamma = self.add_weight(name='gamma',\n",
    "                                 shape=param_shape,\n",
    "                                 initializer='ones',\n",
    "                                 trainable=True)\n",
    "    self.beta = self.add_weight(name='beta',\n",
    "                                shape=param_shape,\n",
    "                                initializer='zeros',\n",
    "                                trainable=True)\n",
    "    super(InstanceNormalization, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    input_shape = inputs.get_shape()\n",
    "    HW = int(input_shape[1])*int(input_shape[2]) \n",
    "    u_ti = 1./HW*np.sum(inputs, axis=(1,2))   \n",
    "    for _ in range(2):\n",
    "      u_ti = np.stack((u_ti, )*input_shape[1], axis=-1) \n",
    "    u_ti = np.swapaxes(u_ti,1,3) \n",
    "    var_ti = 1/HW*np.sum((inputs - u_ti), axis=(1,2))**2\n",
    "    for _ in range(2):\n",
    "      var_ti = np.stack((var_ti, )*input_shape[1], axis=-1) \n",
    "    var_ti = np.swapaxes(var_ti,1,3)                    \n",
    "    y_tijk = (inputs - u_ti) / np.sqrt(var_ti +  self.epsilon)  \n",
    "    return self.gamma * y_tijk + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsampling_Part(tf.keras.Model):\n",
    "  ''' Downsampling part of Generator'''\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(Downsampling_Part, self).__init__()\n",
    "    self.conv1 = Conv2D(64, kernel_size = 7, strides = 1, padding = 'valid')\n",
    "    self.conv2 = Conv2D(128, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv3 = Conv2D(256, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.zeropadding1 = ZeroPadding2D(3)\n",
    "    self.zeropadding2 = ZeroPadding2D(1)\n",
    "    self.zeropadding3 = ZeroPadding2D(1)\n",
    "    self.in1 = InstanceNormalization()\n",
    "    self.in2 = InstanceNormalization()\n",
    "    self.in3 = InstanceNormalization()\n",
    "    self.activation_ReLU = ReLU()\n",
    "  \n",
    "  def call(self, images, labels):\n",
    "    x = input_merge(images,labels)\n",
    "    x = self.zeropadding1(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.in1(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "\n",
    "    x = self.zeropadding2(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.in2(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "\n",
    "    x = self.zeropadding3(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.in3(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "    return x\n",
    "  \n",
    "\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  ''' ResentIdentityBlock for Residual part of Generator'''\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(ResnetIdentityBlock, self).__init__()\n",
    "    self.conv1 = Conv2D(filters=256, kernel_size=3, strides=1, padding='valid')\n",
    "    self.conv2 = Conv2D(filters=256, kernel_size=3, strides=1, padding='valid')\n",
    "    self.zeropadding = ZeroPadding2D(1)\n",
    "    self.in1 = InstanceNormalization()\n",
    "    self.activation_ReLU = ReLU()\n",
    "\n",
    "  def call(self, input_tensor):\n",
    "    x = self.zeropadding(input_tensor)\n",
    "    x = self.conv1(x)\n",
    "    x = self.in(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv2(x)\n",
    "    x += input_tensor\n",
    "    x = self.activation_ReLU(x)\n",
    "    return x\n",
    "\n",
    "  \n",
    "class Bottleneck_Part(tf.keras.Model):\n",
    "  ''' Bottleneck part of Generator'''\n",
    "  def __init__(self):\n",
    "    super(Bottleneck_Part, self).__init__()\n",
    "    self.ResnetIdentityBlock = ResnetIdentityBlock()\n",
    "    \n",
    "  def call(self, input_tensor):\n",
    "    x  = self.ResnetIdentityBlock(input_tensor)\n",
    "    x  = self.ResnetIdentityBlock(x)\n",
    "    x  = self.ResnetIdentityBlock(x)\n",
    "    x  = self.ResnetIdentityBlock(x)\n",
    "    x  = self.ResnetIdentityBlock(x)\n",
    "    x  = self.ResnetIdentityBlock(x)       \n",
    "    return x\n",
    "  \n",
    "\n",
    "class Upsampling_Part(tf.keras.Model):\n",
    "  ''' Upsampling part of Generator'''\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(Upsampling_Part, self).__init__()\n",
    "    self.deconv1 = Conv2DTranspose(128, kernel_size = 4, strides = 2, padding = 'same')\n",
    "    self.deconv2 = Conv2DTranspose(64, kernel_size = 4, strides = 2, padding = 'same')\n",
    "    self.conv1 = Conv2D(3, kernel_size = 7, strides = 1, padding = 'same')\n",
    "    self.zeropadding1 = ZeroPadding2D(1)\n",
    "    self.zeropadding2 = ZeroPadding2D(1)\n",
    "    self.zeropadding3 = ZeroPadding2D(3)\n",
    "    self.activation_ReLU = ReLU()\n",
    "    self.in1 = InstanceNormalization()\n",
    "    self.in2 = InstanceNormalization()\n",
    "\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.deconv1(x)\n",
    "    x = self.in1(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "\n",
    "    x = self.deconv2(x)\n",
    "    x = self.in2(x)\n",
    "    x = self.activation_ReLU(x)\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = tanh(x)\n",
    "    return x\n",
    "  \n",
    "  \n",
    "class Build_generator(tf.keras.Model):\n",
    "  ''' Building a generator'''\n",
    "  def __init__(self):\n",
    "    super(Build_generator, self).__init__()\n",
    "    self.Downsampling = Downsampling_Part()\n",
    "    self.ResidualBlock = Bottleneck_Part()\n",
    "    self.Upsampling = Upsampling_Part()\n",
    "    \n",
    "  def call(self, images, labels):\n",
    "    x = self.Downsampling(images, labels)\n",
    "    x = self.ResidualBlock(x)\n",
    "    x = self.Upsampling(x)\n",
    "    return x\n",
    " \n",
    "\n",
    "class Build_discriminator(tf.keras.Model):\n",
    "  ''' Building a discriminator'''\n",
    "  \n",
    "  def __init__(self, image_size, nd):\n",
    "    super(Build_discriminator, self).__init__()\n",
    "    self.conv1 = Conv2D(64, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv2 = Conv2D(128, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv3 = Conv2D(256, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv4 = Conv2D(512, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv5 = Conv2D(1024, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    self.conv6 = Conv2D(2048, kernel_size = 4, strides = 2, padding = 'valid')    \n",
    "    self.conv7_1 = Conv2D(1, kernel_size = 3, strides = 1)    \n",
    "    self.conv7_2 = Conv2D(nd, kernel_size = int(image_size/64), strides = 1)    \n",
    "    self.zeropadding0 = ZeroPadding2D(0) \n",
    "    self.zeropadding = ZeroPadding2D(1)\n",
    "    self.activation_LeakyReLU = LeakyReLU(alpha=0.01)\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "\n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "    \n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "    \n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "\n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "\n",
    "    x = self.zeropadding(x)\n",
    "    x = self.conv6(x)\n",
    "    x = self.activation_LeakyReLU(x)\n",
    "    \n",
    "    x_src = self.zeropadding(x)\n",
    "    D_src = self.conv7_1(x_src)\n",
    "    D_cls = self.conv7_2(x)\n",
    "\n",
    "    return  D_src, D_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss\n",
    "def adverserial_loss(logits, real=True):\n",
    "  if real == True:\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(logits),logits = logits)\n",
    "  else:\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.zeros_like(logits),logits = logits)\n",
    "  return loss\n",
    "\n",
    "def reconstruction_loss(image,rec_image):\n",
    "  return lambda_rec * tf.reduce_mean(np.abs(image  - rec_image))\n",
    " \n",
    "def domain_cls_loss(domain, logits):\n",
    "  return lambda_cls * tf.losses.sigmoid_cross_entropy(multi_class_labels = domain, logits = logits)\n",
    "\n",
    "def w_adverserial_loss(logits, real=True):\n",
    "  loss = tf.reduce_mean(logits)\n",
    "  if real == True:\n",
    "    loss = -loss\n",
    "  return loss\n",
    "\n",
    "## G_loss, D_loss\n",
    "def G_loss(fake_D_src, target_D_cls, target_domain,input_image, reconstructed_image, lambda_cls,lambda_rec):\n",
    "  loss = w_adverserial_loss(fake_D_src, real=True) + lambda_cls * domain_cls_loss(target_domain, target_D_cls) + lambda_rec * reconstruction_loss(input_image, reconstructed_image)\n",
    "  return loss\n",
    "  \n",
    "def D_loss(real_D_src, fake_D_src, original_domain, original_D_cls, lambda_cls):\n",
    "  loss = w_adverserial_loss(real_D_src, real=True) + w_adverserial_loss(fake_D_src, real=False) + lambda_cls* domain_cls_loss(original_domain,original_D_cls)\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop (training happens here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, original_domain, target_domain, step, i):\n",
    "\n",
    "# fake_image (image) # generator: generated fake images\n",
    "# fake_D_src (logits) # discriminator: real / fake image classification for fake image\n",
    "# target_D_cls (logits) # discriminator: original / target label classification for fake image\n",
    "# real_D_src (logits) # discriminator: real / fake image classificiaion for real image\n",
    "# original_D_cls (logits) # discriminator: original / target label classificiaion for real image\n",
    "# fake_D_src (logits) # discriminator: original/target classification for fake image\n",
    "# reconstructed_image (image) # generator: generated real (reconstructed) images \n",
    "\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "    fake_image = generator(input_image, target_domain)  # step(b)\n",
    "    fake_D_src, target_D_cls = discriminator(fake_image)  # step(d) \n",
    "    reconstructed_image = generator(fake_image, original_domain) # step(c)        \n",
    "    real_D_src, original_D_cls = discriminator(input_image) #step(a) \n",
    " \n",
    "    discriminator_loss = D_loss(real_D_src, fake_D_src, original_domain, original_D_cls, lambda_cls)\n",
    "    generator_loss = G_loss(fake_D_src, target_D_cls, target_domain,input_image, reconstructed_image, lambda_cls,lambda_rec)\n",
    " \n",
    "    # discriminator 5번 우선 업데이트  \n",
    "  gradients_of_discriminator = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "  print (\"Step %d-%d [D loss: %f]\" % (step+1, i+1, discriminator_loss))   \n",
    "\n",
    "  if i == 0: # 처음 한번만 generator 업데이트\n",
    "    gradients_of_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    print (\"Step %d [G loss: %f]\" % (step+1, generator_loss))    \n",
    "\n",
    "def train(train_dataset, steps, batch_size,discriminator_updates):\n",
    "    \n",
    "  for step in range(steps):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(discriminator_updates):\n",
    "        input_image, original_domain = next(iter(train_dataset))\n",
    "        target_domain = random_target_domain_generation(batch_size)\n",
    "        train_step(input_image, original_domain, target_domain, step, i)  \n",
    "        \n",
    "    generate_and_save_images(generator,\n",
    "                             step + 1,\n",
    "                             test_dataset)\n",
    "\n",
    "    if (step + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for step {} is {} sec'.format(step + 1, time.time()-start))\n",
    "\n",
    "  generate_and_save_images(generator,\n",
    "                           step,\n",
    "                           test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 training image loaded \n",
      "10 x 5 original domain dataset loaded\n",
      "Number of train images: 8\n",
      "Number of train original domain labels: 8\n",
      "Number of test images: 2\n",
      "Number of test original domain labels: 2\n"
     ]
    }
   ],
   "source": [
    "attr_csv = '/home/Markkim/Celeb/list_attr_celeba.csv'\n",
    "folder = '/home/Markkim/Celeb/img_align_celeba/'\n",
    "\n",
    "num = 10\n",
    "size = 128\n",
    "\n",
    "X_train, original_domain = data_preprocessing(folder, attr_csv, num, size)\n",
    "X_train, X_test, original_domain_train, original_domain_test = dataset_split(X_train, original_domain, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.dataset generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "test_batch_size = 4\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,original_domain_train))\n",
    "train_dataset = train_dataset.batch(batch_size) \n",
    "train_dataset = train_dataset.map(lambda x, y: _preprocessing(x, y, train=True))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test,original_domain_test))\n",
    "test_dataset = test_dataset.batch(test_batch_size) \n",
    "test_dataset = test_dataset.map(lambda x, y: _preprocessing(x, y, train=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Build_generator()\n",
    "discriminator = Build_discriminator(size, original_domain_train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps = 20\n",
    "lambda_cls = 1\n",
    "lambda_rec = 10\n",
    "lambda_gp = 10\n",
    "train(train_dataset, steps, batch_size, discriminator_updates=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
